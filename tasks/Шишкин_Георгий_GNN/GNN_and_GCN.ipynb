{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"GNN_and_GCN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7d7704b9-6e61-4bf2-8590-4905d56ed5ec"},"source":["# GNN и GCN "],"id":"7d7704b9-6e61-4bf2-8590-4905d56ed5ec"},{"cell_type":"markdown","metadata":{"id":"cHl00wq_DVwq"},"source":["Существует несколько библиотек для работы с GNN, я же остановился на ```torch_geometric```, потому что я хорошо знаком с обычным ```torch```. Здесь будет представлена вводная информация по работе с этой библиотекой и по работе с GNN в целом. Я пытался описать несколько уровней асбстракции и шел от высокой к низкой, по заветам [@jeremyphoward](https://twitter.com/jeremyphoward). Оказалось, что это сложнее, чем я думал -- вот и повод больше ценить его курс."],"id":"cHl00wq_DVwq"},{"cell_type":"markdown","metadata":{"id":"2874c0c7-7be0-4f67-8b4a-c81fdddfc435"},"source":["## Особенности работы с графом в ```torch_geometric```"],"id":"2874c0c7-7be0-4f67-8b4a-c81fdddfc435"},{"cell_type":"markdown","metadata":{"id":"da8e840d-3ed5-4d79-ae85-0f9b8704fa5b"},"source":["### ```torch_geometric.data.Data```"],"id":"da8e840d-3ed5-4d79-ae85-0f9b8704fa5b"},{"cell_type":"markdown","metadata":{"id":"2dd6cd31-c107-46d2-a561-7ba2017f2c6d"},"source":["Cразу же начнем с кода — в библиотеке ```torch_geometric``` для выражения графа выделен отдельный класс ```torch_geometric.data.Data```, имеющий следующие параметры:\n","* ```data.x``` -- матрица признаков каждой вершины\n","* ```data.edge_index``` -- ребра в графе\n","* ```data.eage_attr``` -- атрибуты ребер\n","* ```data.y``` -- таргет\n","* ```data.pos``` -- позиции вершин\n","\n","Для инициализации ```Data``` не нужно указывать всю эту информацию, как будет показано ниже."],"id":"2dd6cd31-c107-46d2-a561-7ba2017f2c6d"},{"cell_type":"markdown","metadata":{"id":"350ea737-c609-45c1-be23-58fea5cd51da"},"source":["<p>Попробуем создать простой граф:</p>\n","<img src=\"./media/graph.svg\" width=500px>"],"id":"350ea737-c609-45c1-be23-58fea5cd51da"},{"cell_type":"markdown","metadata":{"id":"8645f694-0056-4065-a4fc-2780010da3fa"},"source":["Начнем с импорта:"],"id":"8645f694-0056-4065-a4fc-2780010da3fa"},{"cell_type":"code","metadata":{"id":"3a243496-022e-49d7-bd83-b3f6c828937f","executionInfo":{"status":"ok","timestamp":1627490672132,"user_tz":-240,"elapsed":2685,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["import torch\n","from torch_geometric.data import Data"],"id":"3a243496-022e-49d7-bd83-b3f6c828937f","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"71f7ffa1-cdf8-4363-bb5e-226b978064ae"},"source":["Нам понадобится способ описать в виде тензора ребра, самый экономный вариант -- записать их в виде пар:"],"id":"71f7ffa1-cdf8-4363-bb5e-226b978064ae"},{"cell_type":"code","metadata":{"id":"86a4d7ee-61f7-4752-8540-277f4552c7fd","executionInfo":{"status":"ok","timestamp":1627490684212,"user_tz":-240,"elapsed":412,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["edge_index = torch.tensor([[0, 1],\n","                           [1, 0],\n","                           [1, 2],\n","                           [2, 1]], dtype=torch.long)"],"id":"86a4d7ee-61f7-4752-8540-277f4552c7fd","execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"122dae0f-0d23-444d-abd8-98f31ed5b8ea"},"source":["Однако такой формат не пойдет. Тензор должен иметь размер ```[2, num_edges]```, то есть или ```edge_index``` придется транспонировать отдельно (а затем ещё и, по хорошему, вызывать ```contiguous()```), или приучить себя сразу писать в такой форме:"],"id":"122dae0f-0d23-444d-abd8-98f31ed5b8ea"},{"cell_type":"code","metadata":{"id":"5e051b7c-0f73-484d-9fed-dd3fb399fd73","executionInfo":{"status":"ok","timestamp":1627490711453,"user_tz":-240,"elapsed":257,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["edge_index = torch.tensor([[0, 1, 1, 2],\n","                           [1, 0, 2, 1]], dtype=torch.long)"],"id":"5e051b7c-0f73-484d-9fed-dd3fb399fd73","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eecf49cb-55d8-42bf-ae98-0fe71dea838c"},"source":["Далее нам потребуется тензор для описания признаков каждой вершины. Важно: ```x.dim() == 2```, так как ```x``` должен иметь размер ```[num_nodes, num_dimensions]```"],"id":"eecf49cb-55d8-42bf-ae98-0fe71dea838c"},{"cell_type":"code","metadata":{"id":"f0577de5-5214-4f18-8be0-c4f2f44563fb","executionInfo":{"status":"ok","timestamp":1627490745502,"user_tz":-240,"elapsed":864,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["x = torch.tensor([[-1], [0], [1]], dtype=torch.float)"],"id":"f0577de5-5214-4f18-8be0-c4f2f44563fb","execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"42f389bd-25f4-4dc8-a938-cbfe42326968"},"source":["Собрав все вместе получаем:"],"id":"42f389bd-25f4-4dc8-a938-cbfe42326968"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3da6d28f-b4a0-4755-868d-ad0cd4991e55","executionInfo":{"status":"ok","timestamp":1627490747874,"user_tz":-240,"elapsed":6,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}},"outputId":"52178edb-f7ca-4473-8e76-edb1ba60c3de"},"source":["data = Data(x=x, edge_index=edge_index)\n","data"],"id":"3da6d28f-b4a0-4755-868d-ad0cd4991e55","execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(edge_index=[2, 4], x=[3, 1])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"1e262b19-3f18-48ff-9da8-b3b798262c38"},"source":["### Датасеты: Cora "],"id":"1e262b19-3f18-48ff-9da8-b3b798262c38"},{"cell_type":"markdown","metadata":{"id":"a229e792-2cf1-47c5-80d9-a017db36691c"},"source":["От единичных графов к датасетам, возьмем для примера Cora. Заодно попробуем построить первую модель с использованием ```GCN```, пока не углубляясь в принципы её работы. Но сначала добавим немного контекста данным. \n","\n","Cora — это датасет, в котором вершины представляют научные статьи, а ребра — ссылки на эти статьи. Каждая вершина выражается 1433 призаками и имеет один из 7 классов. Фактически эти 1433 признака ничто иное как bag-of-words репрезентация названия. Важно понять, что создатели пошли на условность — ведь в конкретно этом случае $a_{ij}=a_{ji}=1$. "],"id":"a229e792-2cf1-47c5-80d9-a017db36691c"},{"cell_type":"code","metadata":{"id":"2f57e64e-75bb-43e9-af7f-8d5bda4a8d7b","executionInfo":{"status":"ok","timestamp":1627490797083,"user_tz":-240,"elapsed":3117,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","import torch_geometric.transforms as T\n","from torch_geometric.nn import GCNConv"],"id":"2f57e64e-75bb-43e9-af7f-8d5bda4a8d7b","execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d014511c-8681-4d89-ae61-92089c7526a3"},"source":["Загрузка датасета. Заметьте, что мы также можем применять дополнительные трансформации к данным:"],"id":"d014511c-8681-4d89-ae61-92089c7526a3"},{"cell_type":"code","metadata":{"id":"1de9cc4b-0aef-4d67-b8e4-e39ccfe485e4","executionInfo":{"status":"ok","timestamp":1627490840435,"user_tz":-240,"elapsed":275,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["dataset = Planetoid(root='./data', name='Cora', transform=T.NormalizeFeatures())"],"id":"1de9cc4b-0aef-4d67-b8e4-e39ccfe485e4","execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"224d85c2-7b48-4f10-8be5-e4079ad1539d"},"source":["В данном случае мы нормализовали ```dataset.data.x``` по строкам. Взглянем на объект класса ```Data``` -- атрибут датасета:"],"id":"224d85c2-7b48-4f10-8be5-e4079ad1539d"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6e705c1-1f08-41fd-af29-0d9fbbab4ae5","executionInfo":{"status":"ok","timestamp":1627490850279,"user_tz":-240,"elapsed":420,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}},"outputId":"082853af-44f4-409e-bdd8-26ce23927778"},"source":["data = dataset.data\n","data"],"id":"a6e705c1-1f08-41fd-af29-0d9fbbab4ae5","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"f0e60ac0-518f-47fd-9d3a-77f9bc111bed"},"source":["Здесь дела обстоят интереснее, чем в нашем игрушечном графе выше. На весь датасет -- один граф с 2708 вершинами (это видно по ```x```), предсказания нужно делать на уровне вершин, ведь таргетов у нас тоже 2708 (это видно по ```y```). Тренировачные, валидационные и тестовые данные находятся в этом же графе -- для них существуют свои маски со значениями ```True/False```. Ребер же в датасете -- 5278 (10556 / 2)."],"id":"f0e60ac0-518f-47fd-9d3a-77f9bc111bed"},{"cell_type":"markdown","metadata":{"id":"1e4cc1b1-aede-4042-9f79-364708bae52f"},"source":["## Модель с GCN слоями  "],"id":"1e4cc1b1-aede-4042-9f79-364708bae52f"},{"cell_type":"code","metadata":{"id":"40321722-0b65-46fe-8360-7c941ffd6310","executionInfo":{"status":"ok","timestamp":1627490903157,"user_tz":-240,"elapsed":334,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["class Net(torch.nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = GCNConv(dataset.num_features, 16, cached=True)\n","        self.conv2 = GCNConv(16, dataset.num_classes, cached=True)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)"],"id":"40321722-0b65-46fe-8360-7c941ffd6310","execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5a0c710-48e6-4978-8444-0bbec13b77b3"},"source":["Все как всегда -- ```nn.Module```, ```forward```, разница лишь в наличии новых слоев ```GCNConv``` -- первый с 16 выходными каналами, второй -- с 7. Похоже на обычный линейный слой. ```forward``` на вход будет принимать весь граф, внутри себя вычленять матрицу признаков и матрицу ребер, пропускать через конволюционные слои, функции активации и Dropout -- очень похоже на обычную модель.\n","\n","Как обычно будет протекать и обучение: "],"id":"b5a0c710-48e6-4978-8444-0bbec13b77b3"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2dd780d-16a6-4cf3-9097-d4b95df26747","executionInfo":{"status":"ok","timestamp":1627490941182,"user_tz":-240,"elapsed":37636,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}},"outputId":"1f380a84-b063-48f5-b6a4-90894b1a533b"},"source":["device='cuda'\n","model, data = Net().to(device), data.to(device)\n","optimizer = torch.optim.Adam([\n","    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n","    dict(params=model.conv2.parameters(), weight_decay=0)\n","], lr=0.01)\n","\n","best_val_acc = 0\n","for epoch in range(0, 150):\n","    \n","    model.train()\n","    optimizer.zero_grad()\n","    t = model(data)\n","    train_loss = F.nll_loss(t[data.train_mask], data.y[data.train_mask])\n","    train_loss.backward()\n","    optimizer.step()\n","    \n","    \n","    model.eval()\n","    accs = []\n","    for mask in [data.train_mask, data.val_mask]:\n","        pred = t[mask].max(1)[1]\n","        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n","        accs.append(acc)\n","    \n","    val_loss = F.nll_loss(t[data.val_mask], data.y[data.val_mask])\n","    train_acc, val_acc = accs\n","        \n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","    \n","    if (epoch) % 10 == 0:\n","        log = 'Epoch: {:03d}, Train: {:.4f}, Train_loss: {:.4f} Val: {:.4f} Val_loss: {:.4f}'\n","        print(log.format(epoch, train_acc, train_loss, val_acc, val_loss))"],"id":"d2dd780d-16a6-4cf3-9097-d4b95df26747","execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch: 000, Train: 0.2214, Train_loss: 1.9504 Val: 0.1820 Val_loss: 1.9398\n","Epoch: 010, Train: 0.9286, Train_loss: 0.7636 Val: 0.6840 Val_loss: 1.2537\n","Epoch: 020, Train: 0.9714, Train_loss: 0.2328 Val: 0.7280 Val_loss: 0.8889\n","Epoch: 030, Train: 0.9857, Train_loss: 0.1080 Val: 0.6980 Val_loss: 0.9714\n","Epoch: 040, Train: 1.0000, Train_loss: 0.0571 Val: 0.7080 Val_loss: 0.9899\n","Epoch: 050, Train: 1.0000, Train_loss: 0.0418 Val: 0.7320 Val_loss: 0.8939\n","Epoch: 060, Train: 1.0000, Train_loss: 0.0407 Val: 0.7480 Val_loss: 0.9238\n","Epoch: 070, Train: 1.0000, Train_loss: 0.0435 Val: 0.7280 Val_loss: 0.8863\n","Epoch: 080, Train: 1.0000, Train_loss: 0.0310 Val: 0.7280 Val_loss: 0.9531\n","Epoch: 090, Train: 1.0000, Train_loss: 0.0474 Val: 0.7040 Val_loss: 0.9445\n","Epoch: 100, Train: 0.9929, Train_loss: 0.0359 Val: 0.7420 Val_loss: 0.9032\n","Epoch: 110, Train: 1.0000, Train_loss: 0.0239 Val: 0.7100 Val_loss: 0.9895\n","Epoch: 120, Train: 0.9857, Train_loss: 0.0512 Val: 0.7220 Val_loss: 0.8958\n","Epoch: 130, Train: 1.0000, Train_loss: 0.0334 Val: 0.7220 Val_loss: 1.0029\n","Epoch: 140, Train: 0.9929, Train_loss: 0.0378 Val: 0.7400 Val_loss: 0.9960\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ac4f090e-8f77-4fc9-ae11-1075745b84cd"},"source":["Результат на тестовых данных:"],"id":"ac4f090e-8f77-4fc9-ae11-1075745b84cd"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2114258e-721f-4c9c-9515-c1161720ba83","executionInfo":{"status":"ok","timestamp":1627490948305,"user_tz":-240,"elapsed":277,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}},"outputId":"54e92329-2924-46dd-fab2-bb5cda36f174"},"source":["t = model(data)[data.test_mask]\n","F.nll_loss(t, data.y[data.test_mask]).item(), t.max(1)[1].eq(data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()"],"id":"2114258e-721f-4c9c-9515-c1161720ba83","execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.6377240419387817, 0.804)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"e8160b32-1576-4d0b-a882-1bd0423f10a0"},"source":["Могло бы быть и лучше, на [Papers with code](https://paperswithcode.com/sota/node-classification-on-cora) ```GCN``` дает результат в 81.5%. Однако пример выше служит другим целям -- я хотел показать как просто можно написать графовую сеть. Правда, это просто ровно до тех пор пока вы не решите углубиться."],"id":"e8160b32-1576-4d0b-a882-1bd0423f10a0"},{"cell_type":"markdown","metadata":{"id":"188a9024-3b62-4f33-b886-92b2f2d7a89c"},"source":["## Немного математики и ```GCNConv``` "],"id":"188a9024-3b62-4f33-b886-92b2f2d7a89c"},{"cell_type":"markdown","metadata":{"id":"8b984bc4-83dd-45b6-a8b4-2959f05fbbca"},"source":["```GCNConv``` впервые появился в статье [Semi-supervised Classification with Graph Convolutional Networks](https://arxiv.org/pdf/1609.02907.pdf). Взглянем на довольно пугающую формулу для одной вершины:\n","$$x'_i = \\Theta \\sum_{\\mathcal{N(i) \\cup \\{i\\}}} \\frac{e_{i,j}}{\\sqrt{\\hat d_i \\hat d_j}}x_j$$\n","...что легко можно интерпретировать как ужас во плоти. Но если отбросить самое страшное то получится что-то вроде:\n","$$x'_i = \\Theta \\sum_{j} c(i, j)x_j$$\n","То есть взвешенная сумма признаков перемноженная с параметрами $\\Theta$. Ещё чуть-чуть и будет похоже на обычное произведение матрицы признаков на линейный слой. Теперь постепенно будем возвращать страшные штуки и начнем с критериев суммы.\n","\n","$\\mathcal{N(i)}$ есть ничто иное как соседи вершины $i$ (то есть вершины имеющие общее ребро с $i$). Приписка $\\cup \\{i\\}$ значит \"включая вершину $i$\". Иными словами, мы взвешенно суммируем признаки соседей и самой вершины.\n","\n","Теперь $c(i, j)$. Числитель $e_{i,j}$ есть вес ребра (по умолчанию = 1.0). $\\hat d_j = 1 + \\sum_{j\\in\\mathcal{N(i)}} e_{i,j}$, то есть в случае по умолчанию (c единичным значением веса ребра) $\\hat d_j$ значит 1 + количество соседей вершины $j$."],"id":"8b984bc4-83dd-45b6-a8b4-2959f05fbbca"},{"cell_type":"markdown","metadata":{"id":"4a14abdd-8bec-4938-98a5-f92d9ae138df"},"source":["Ну а теперь в матричном виде:  $$X' = \\hat D ^ {-0.5} \\hat A \\hat D ^ {-0.5} X \\Theta$$ где $\\hat A = A + I$. $A$ - матрица смежности графа, $I$ - единичная матрица, а значит $\\hat A$ - матрица смежности с петлями (петля - ребро, начало и конец которого находятся в одной и той же вершине). Матрица $\\hat D$ инициализируется как $D_{ii} = \\sum_{j=0}\\hat A_{ij}$, то есть диагональная матрица."],"id":"4a14abdd-8bec-4938-98a5-f92d9ae138df"},{"cell_type":"markdown","metadata":{"id":"717b459c-0803-4163-9727-672e44cdbeba"},"source":["Возьмем первую формулу и успростим её (основываясь на предположении что вес ребер = 1.0). Получится:\n","$$x_i'= \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\hat d_i \\hat d_j}}  \\left( {\\Theta} x_j \\right)$$"],"id":"717b459c-0803-4163-9727-672e44cdbeba"},{"cell_type":"markdown","metadata":{"id":"fd5fbad7-3532-463f-bba2-0f355c641d4a"},"source":["### ```MessagePassing```"],"id":"fd5fbad7-3532-463f-bba2-0f355c641d4a"},{"cell_type":"markdown","metadata":{"id":"c23d76a9-0f8f-4bd3-a354-4a007a03a952"},"source":["Перед имплементацией поговорим о базовом классе ```MessagePassing``` (то же что и ```nn.Module```, но для графов). В его основе лежит форммула для обобщения GNN слоев: \n","\n","$$x_i^{(k)} = \\gamma^{(k)} \\left( x_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(x_i^{(k-1)}, x_j^{(k-1)},e_{j,i}\\right) \\right)\n","$$\n","\n","Она тоже страшная, и для нее выделен отдельный раздел ниже. Пока что небольшие пояснения:\n","* $\\square$ -- дифференцируемая, независимая от порядка следования членов функция (например: сумма, среднее, минимум и т.д), называемая функцией агрегации\n","* $\\gamma$ и $\\phi$ -- дифференцируемые функции, такие как перцептрон\n","\n","Перенося на реалии ```GCNConv```:\n","* $\\square$ есть $\\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}}$\n","* $\\phi$ есть $\\frac{1}{\\sqrt{\\hat d_i \\hat d_j}}  \\left( {\\Theta} x_j \\right)$\n","* $\\gamma$ отсутствует\n","\n","(<i>В самом же коде функции поменяют своё содержание ради простоты</i>)\n","\n","Возвращаясь к классу ```MessagePassing```, грубо говоря, для каждой функции выше есть зарезервированные имена, которые нужно самому инициализировать при наследовании (как тот же ```forward()```). Методы класса ```MessagePassing```:\n","* ```MessagePassing.propagate(edge_index, size=None, **kwargs)``` -- метод вызывающий ```MessagePassing.message()``` и ```MessagePassing.update()```\n","* ```MessagePassing.message(...)``` -- то же что и $\\phi$\n","* ```MessagePassing.update(aggr_out, ...)``` -- то же что и $\\gamma$\n","\n","для выбора функции агрегации ($\\square$) на инициализации нужно будет указать параметр ```aggr=```"],"id":"c23d76a9-0f8f-4bd3-a354-4a007a03a952"},{"cell_type":"markdown","metadata":{"id":"9702aeba-4d0b-477a-ac1a-6f0400868214"},"source":["Для того чтобы создать ```GCNConv``` потребуется:\n","1. Добавить в матрицу смежности петель\n","2. Линейно преобразовать матрицу признаков\n","3. Посчитать коэфициенты нормализации -- $c(i,j)$\n","4. Применить коэфициенты нормализации\n","5. Суммировать значения соседних вершин"],"id":"9702aeba-4d0b-477a-ac1a-6f0400868214"},{"cell_type":"code","metadata":{"id":"f2e206ba-35f6-4fa5-acc7-f52e2e758efa","executionInfo":{"status":"ok","timestamp":1627491163477,"user_tz":-240,"elapsed":719,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree"],"id":"f2e206ba-35f6-4fa5-acc7-f52e2e758efa","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"6edeeb6c-c6d2-4547-ac1d-004ce6850471","executionInfo":{"status":"ok","timestamp":1627491164368,"user_tz":-240,"elapsed":9,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["class GCN_udv(MessagePassing):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCN_udv, self).__init__(aggr='add')\n","        self.lin = torch.nn.Linear(in_channels, out_channels, bias=False)\n","        \n","    def forward(self, x, edge_index):        \n","        # Step 1\n","        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n","        \n","        # Step 2\n","        x = self.lin(x)\n","        \n","        # Step 3\n","        row, col = edge_index\n","        deg = degree(col, x.size(0), dtype=x.dtype)\n","        deg_inv_sqrt = deg.pow(-0.5)\n","        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","        \n","        # Step 4-5\n","        return self.propagate(edge_index, x=x, norm=norm)\n","    \n","    def message(self, x_j, norm):\n","        \n","        # Step 4\n","        return norm.view(-1, 1) * x_j"],"id":"6edeeb6c-c6d2-4547-ac1d-004ce6850471","execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"51c0adc9-f453-418e-b724-fe264e4836e8"},"source":["Теперь попробуем вставить наш слой в самую первую модель:"],"id":"51c0adc9-f453-418e-b724-fe264e4836e8"},{"cell_type":"code","metadata":{"id":"7027f8ce-1f8b-4364-8272-3d5e2cb81b76","executionInfo":{"status":"ok","timestamp":1627491166388,"user_tz":-240,"elapsed":8,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}}},"source":["class Net(torch.nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = GCN_udv(dataset.num_features, 16)\n","        self.conv2 = GCN_udv(16, dataset.num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)"],"id":"7027f8ce-1f8b-4364-8272-3d5e2cb81b76","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b685ae31-6865-4533-b7f2-ab756399e511","executionInfo":{"status":"ok","timestamp":1627491170112,"user_tz":-240,"elapsed":1138,"user":{"displayName":"Tired Jesus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3C0xEQRf6CO-4hc6wAfy-lQQhBXreEvjfLKzJ=s64","userId":"15792976198967038670"}},"outputId":"291b6b4e-80f1-41dc-daa4-39e7e68a27d1"},"source":["device='cuda'\n","model, data = Net().to(device), data.to(device)\n","optimizer = torch.optim.Adam([\n","    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n","    dict(params=model.conv2.parameters(), weight_decay=0)\n","], lr=0.01)\n","\n","best_val_acc = 0\n","for epoch in range(0, 150):\n","    \n","    model.train()\n","    optimizer.zero_grad()\n","    t = model(data)\n","    train_loss = F.nll_loss(t[data.train_mask], data.y[data.train_mask])\n","    train_loss.backward()\n","    optimizer.step()\n","    \n","    \n","    model.eval()\n","    accs = []\n","    for mask in [data.train_mask, data.val_mask]:\n","        pred = t[mask].max(1)[1]\n","        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n","        accs.append(acc)\n","    \n","    val_loss = F.nll_loss(t[data.val_mask], data.y[data.val_mask])\n","    train_acc, val_acc = accs\n","        \n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","    \n","    if (epoch) % 10 == 0:\n","        log = 'Epoch: {:03d}, Train: {:.4f}, Train_loss: {:.4f} Val: {:.4f} Val_loss: {:.4f}'\n","        print(log.format(epoch, train_acc, train_loss, val_acc, val_loss))"],"id":"b685ae31-6865-4533-b7f2-ab756399e511","execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch: 000, Train: 0.1214, Train_loss: 1.9460 Val: 0.1540 Val_loss: 1.9450\n","Epoch: 010, Train: 0.9429, Train_loss: 0.9933 Val: 0.6640 Val_loss: 1.4260\n","Epoch: 020, Train: 0.9357, Train_loss: 0.3292 Val: 0.6800 Val_loss: 1.0647\n","Epoch: 030, Train: 0.9786, Train_loss: 0.1472 Val: 0.7200 Val_loss: 0.9840\n","Epoch: 040, Train: 1.0000, Train_loss: 0.0646 Val: 0.7320 Val_loss: 0.8916\n","Epoch: 050, Train: 0.9857, Train_loss: 0.0714 Val: 0.7380 Val_loss: 0.8796\n","Epoch: 060, Train: 0.9929, Train_loss: 0.0387 Val: 0.7300 Val_loss: 0.9120\n","Epoch: 070, Train: 1.0000, Train_loss: 0.0447 Val: 0.7220 Val_loss: 0.9112\n","Epoch: 080, Train: 1.0000, Train_loss: 0.0487 Val: 0.7460 Val_loss: 0.9167\n","Epoch: 090, Train: 1.0000, Train_loss: 0.0623 Val: 0.7240 Val_loss: 0.8935\n","Epoch: 100, Train: 1.0000, Train_loss: 0.0344 Val: 0.7340 Val_loss: 0.9100\n","Epoch: 110, Train: 1.0000, Train_loss: 0.0490 Val: 0.7340 Val_loss: 0.8824\n","Epoch: 120, Train: 1.0000, Train_loss: 0.0320 Val: 0.7400 Val_loss: 0.8830\n","Epoch: 130, Train: 0.9929, Train_loss: 0.0335 Val: 0.7320 Val_loss: 0.9302\n","Epoch: 140, Train: 1.0000, Train_loss: 0.0308 Val: 0.7400 Val_loss: 0.8947\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"60d6ab46-2445-4929-b5b0-dc74fef36282"},"source":["## Много математики и GNN "],"id":"60d6ab46-2445-4929-b5b0-dc74fef36282"},{"cell_type":"markdown","metadata":{"id":"a6fc709f-532e-4b4c-8edc-a43e7956bc5f"},"source":["### Чем примечательны графы? "],"id":"a6fc709f-532e-4b4c-8edc-a43e7956bc5f"},{"cell_type":"markdown","metadata":{"id":"08303c09-6a0b-4710-86ff-4ba6f18a7e48"},"source":["Начать нужно с особенностей данных — предполагается что графы не упорядочены — у них обычно нет начала и конца. Вершины же имеют свои признаки (features), поэтому когда мы пытаемя выразить матрицу в виде стандартного тензора (пока что будем считать что у описываемого графа нет ребер): \n","$$ X = \\begin{bmatrix}x_1 & x_2 & ... & x_n \\end{bmatrix}^T  $$\n","\n","Порядок уже появляется. Нам же важно, чтобы этот порядок не влиял на результат некоторой функции $f(X)$. Для того чтобы описать это математически введем матрицу перемешивания $P$. Как пример:\n","$$P_{(2,4,1,3)}X = \\begin{bmatrix}0 & 1& 0 & 0 \\\\ 0 & 0& 0 & 1 \\\\ 1 & 0& 0 & 0\\\\ 0 & 0& 1 & 0\\end{bmatrix} \\begin{bmatrix}-x_1- \\\\ -x_2-\\\\ -x_3- \\\\ -x_4-\\end{bmatrix} =\\begin{bmatrix}-x_2- \\\\ -x_4-\\\\ -x_1- \\\\ -x_3-\\end{bmatrix}$$"],"id":"08303c09-6a0b-4710-86ff-4ba6f18a7e48"},{"cell_type":"markdown","metadata":{"id":"fd672534-3be9-4131-b90c-9a3fc8e9f5f4"},"source":["Количество таких матриц — факториал от количества вершин и для каждой должно выполняться условие:\n","$$ f(PX) = f(X) $$\n","Это есть <b>permutation invariance</b> (надеюсь появились флешбеки к прошлому разделу).\n","\n","Но что если нам нам нужны предсказания на уровне каждой вершины? Результат функции должен быть также подвержен перестановке:\n","$$ f(PX) = Pf(X) $$\n","Это есть <b>permutation equivariance</b>\n","\n","\n","...это значит что мы можем рассматривать каждую строку отдельно как превращение признаков вершины в латентный вектор:\n","$$ h_i = \\psi (x_i) \\\\ H = f(X) $$\n","\n","Если же добавить инвариантность:\n","\n","$$ f(X) = \\phi (\\bigoplus_{i \\in V} \\psi(x_i)) $$\n","\n","$\\bigoplus$ -- инвариантная функция агрегации"],"id":"fd672534-3be9-4131-b90c-9a3fc8e9f5f4"},{"cell_type":"markdown","metadata":{"id":"376ceb28-9d4d-4148-9098-61518675a10c"},"source":["Добавим в граф смежную матрицу $A$, теперь функция принимает два параметра -- $f(X, A)$. Матрица $A$ симметрична, значит перемешивать нужно и колоны, и строки. Добиться этого можно с помощью $PAP^T$. В таком случае словия:\n","* Инвариантности: $f(PX, PAP^T) = f(X, A) $\n","* Эквариантности: $f(PX, PAP^T) = Pf(X,A) $\n","\n","Добавление матрицы смежности значит добавление ценности связям вершин. Множество соседей описывается как:\n","$$\\mathcal{N}_i = \\{j : (i, j) \\in E \\vee (j, i) \\in E\\}$$\n","Тогда множество фич соседей:\n","$$X_{\\mathcal{N}_i} = \\{\\{x_j : j \\in \\mathcal{N}_i\\}\\}$$\n","Определим локальную функцию $g(x_i, X_{\\mathcal{N}_i})$ оперерирующую на этом множестве. В таком случае, как часть $f(X, A)$, она эквариантна:\n","$$f(X, A) = \\begin{bmatrix}-g(x_0, X_{\\mathcal{N}_0})- \\\\ -g(x_1, X_{\\mathcal{N}_1})-\\\\ ... \\\\ -g(x_n, X_{\\mathcal{N}_n})-\\end{bmatrix}$$"],"id":"376ceb28-9d4d-4148-9098-61518675a10c"},{"cell_type":"markdown","metadata":{"id":"8eae5861-c061-411e-a7bd-a5e0cf668e4a"},"source":["<p>Теперь же попробуем определить $g$ и наконец таки выйдем на знакомую землю. $g$ (результат которой, я напомню, $h_i$) разделяется на несколько типов:</p>\n","<img src='./media/types_of_gnn.png'>"],"id":"8eae5861-c061-411e-a7bd-a5e0cf668e4a"},{"cell_type":"markdown","metadata":{"id":"59a048fe-d663-46c0-9924-abbbd0fca2e3"},"source":["Разница между ними в том как считается коэфициент перед каждым соседом. Надеюсь вы узнали общую формулу ```MessagePassing```. В ```GCNConv```, раз это конволюционная сеть, коэфициент не является параметром для обучения, но в определенном смысле константа, хоть мы и выразили класс через ```MessagePassing```."],"id":"59a048fe-d663-46c0-9924-abbbd0fca2e3"},{"cell_type":"markdown","metadata":{"id":"59d23eca-a68e-4593-95b3-7220882c21d2"},"source":["### Как использовать GNN? "],"id":"59d23eca-a68e-4593-95b3-7220882c21d2"},{"cell_type":"markdown","metadata":{"id":"05db2cc7-5d20-49ba-aee7-caac2d0f2a74"},"source":["<p>По своей сути GNN преобразовывает признаки каждой вершины (беря в расчет признаки её соседа) в новые признаки и уже из них извлекает пользу, как показано ниже:</p>\n","<img src='./media/gnn_usage.png'>"],"id":"05db2cc7-5d20-49ba-aee7-caac2d0f2a74"},{"cell_type":"code","metadata":{"id":"5fea3d55-c304-49de-afb2-935451c2d72f"},"source":[""],"id":"5fea3d55-c304-49de-afb2-935451c2d72f","execution_count":null,"outputs":[]}]}